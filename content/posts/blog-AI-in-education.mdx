---
title: AI in EdTech - Observations and Opportunities
slug: ai-in-education
heroImage: https://tgq565ix1n.ufs.sh/f/ck6yA5hy4GoxvrG0X7Qd4MO9xGlFAsZkNpmCq8jEzUB72wrQ
description: >-
  Reflecting on the ATXpo 2025 student panel discussion and the evolving role of AI in education.
tags:
  - blog
  - artificial-intelligence
  - panel
  - sjsu
added: "October 6, 2025"
updated: "November 2, 2025"
hidden: false
---

Recently, I was invited to participate in a student panel discussion at [ATXpo 2025](https://atxpo.org/atxpo-2025/?utm_source=vivekraman.dev).
The panel, titled _AI to Z in Ed Tech: Impact, Innovation, and Literacy_, primarily discussed the effects of generative AI on teaching methods. It encompassed faculty and student sentiment, and how universities work towards improving AI literacy among students, faculty, and staff.

I'd like to briefly document my opinions on the subject.

# Adoption of GenAI among students

Generative AI technology sees increasing adoption among students, but some students object to the use of GenAI, citing a lack of belief in the technology.
Additionally, a natural reaction to news saying that jobs are being cut and people are being "replaced" by AI would be to reject it.

I believe that a strong reason for this is a lack of understanding in the technology itself.
We are generally apprehensive of things that are foreign to us.
It may help to present students with real use-cases of generative AI supercharging professionals and researchers of various fields.

# Adoption of GenAI among faculty

Faculty of various departments also tend to prohibit AI use for classroom assignments and homework.
While this is required for a few subjects, a realistic perspective is that students will exploit and work around restrictions.

It's important to consider that these tools have established themselves as part of students' lives.
Even more so, we have the opportunity to stop the cognitive offloading that these tools tend to do.
Similar to how math changed with the advent of the calculator, we should look towards altering our course content and ensure that the student will learn something despite using AI.

Another perspective to this issue is that if AI is able to perform an entire assignment, maybe the assignment could re-focus towards teaching students to write better prompts that efficiently complete the work.
It is, after all, a skill to be learned and practiced.

Solving the issue of generative AI is a good time to reflect on the course learning outcomes (CLOs).
The skills taught in a course:
- May not be adversely changed by generative AI
- May be broken down into smaller steps that are solved by generative AI
- May be made trivially easy by generative AI

In each of these cases, consider the following:
- Can we introduce AI into the mix? AI tends to bring improvements to our efficiency, so it may be a good idea to incorporate AI.
- Is the focus of the course on solving the problem or on the steps itself? Maybe encourage students to think at a higher level, so the problems becomes a part of a whole.
- There's value in teaching students how to efficiently use AI. This would involve centering the course around the AI tool itself, but this may not be as bad as it sounds! Computer-assisted drawing (CAD) completely took over engineering drawing, but that didn't turn out so bad for us.

# Adoption of GenAI among researchers

It is clear that generative AI has pushed out most other avenues of research.
A good indicator of this is a masters program's elective list, as these generally follow fields with ongoing research.
Personally, I have not been able to find classes for Information Security, since there was no faculty teaching it.
Also, a friend of mine who is completing their doctorate program elsewhere was told to basically abandon their research and pivot to AI, because of a lack of funding for anything else.

# Adoption of GenAI among organizations

Some orgs are in a difficult spot.
Doubling down on AI turned out to be a mistake, as infamously reported by [Klarna](https://www.livemint.com/companies/news/klarnas-ai-replaced-700-workers-now-the-fintech-ceo-wants-humans-back-after-40b-fall-11747573937564.html?utm_source=vivekraman.dev), [IBM](https://evidencenetwork.ca/ibm-laid-off-8000-employees-to-replace-them-with-ai-but-what-they-didnt-expect-was-having-to-rehire-as-many-due-to-ai/?utm_source=vivekraman.dev), and more.
It appears that organizations are not entirely sure _how_ AI should replace humans without compromising on quality.
This is a gap that educators and researchers need to fill.
The goal of a university is to generate skilled labour to power tomorrow's workforce.
So, we need to adapt the technology into our courses, and ensure that s tudents are equipped to use it in the right way, maximizing efficiency without compromising quality.

# A note to LLM providers

The technology hinges on learning on the data of your users, but this results in privacy concerns.
Steps should be taken towards scaling back and deploying on embedded devices like smartphones.
An argument can be made that the privacy concerns are overplayed, and that standard fingerprinting is already far more pervasive, but that does not discount the fact that privacy is a viable feature for an LLM to uphold, and there is little reason not to improve it.

# Conclusion

- AI literacy needs to increase, especially among non-technical majors.
- Faculty should reflect on their CLOs, aiming to welcome generative AI instead of trying to shun it.
- Students need to raise the bar. Expectations are higher than ever before, so its important to make sure you are learning every day.
- For technology to succeed, it needs to have widespread approval. You don't see the world wide web polarizing people, but you do see blockchain doing so.
